- _balancing_ loops pressure a stock to decrease
- _reinforcing_ loops pressure a stock to increase
- _dominance_ refers to a loop that has a stronger influence than the others
    - dominance can _shift_ in a system
- _delays_ are an important component of such systems; feedback is almost never immediate, so operators within the system are often making decisions with stale information and must deal with lags

"System dynamics models explore possible futures and ask 'what if' questions" (p47)

what keeps systems working:

- _resilience_: "'the ability to bounce or spring back into shape, position, etc. after being pressed or stretched. Elasticity. ...' ... The opposite of resilience is brittleness or rigidity. Resilience arises from a rich structure of many feedback loops that can work in different ways to restore a system even after a large perturbation. ... Resilience is provided by several such loops, operating through different mechanisms, at different time scales, and with redundancy". _meta-resilience_ is possible too in which a system can become better at becoming resilient.
- _self-organization_: "ability to learn, diversify, complexify, evolve. ... capacity of a system to make its own structure more complex ... Self-organization produces heterogeneity and unpredictability. It is likely to come up with whole new structures, whole new ways of doing things. It requires freedom and experimentation, and a certain amount of disorder. These conditions that encourage self-organization often can be scary for individuals and threatening to power structures."
- _hierarchy_: "organized in subsystems aggregated into larger subsystems, aggregated into still larger subsystems. ... If subsystems can largely take care of themselves, regulate themselves, maintain themselves, and yet serve the needs of the larger system, while the larger system coordinates and enhances the functioning of the subsystems, a stable, resilient, and efficient structure results. ... In hierarchical systems relationships _within_ each subsystem are denser and stronger than relationships _between_ subsystems. ... To be a highly functional system, hierarchy must balance the welfare, freedoms, and responsibilities of the subsystems and total system--there must be enough central control to achieve coordination toward the large-system goal and enough autonomy to keep all subsystems flourishing, functioning, and self-organizing."

---

Chapter 4: Why Systems Surprise Us

> 1. Everything we think we know about the world is a model. Every word and every language is a model. All maps and statistics, books and databases, equations and computer programs are models. So are the ways I picture the world in my head--my _mental_ models. None of these is or ever will be the _real_ world.
> 2. Our models usually have a strong congruence with the world. That is why we are such a successful species in the biosphere. Especially complex and sophisticated are the mental models we develop from direct, intimate experience of nature, people, and organizations immediately around us.
> 3. However, and conversely, our models fall far short of representing the world fully. That is why we make mistakes and why we are regularly surprised. In our heads, we can keep track of only a few variables at one time. We often draw illogical conclusions from accurate assumptions, or logical conclusions from inaccurate assumptions. Most of us, for instance, are surprised by the amount of growth an exponential process can generate. Few of us can intuit how to damp oscillations in a complex system.

...

> You can't navigate well in an interconnected, feedback-dominated world unless you take your eyes off short-term events and look for long-term behavior and structure; unless you are aware of false boundaries and bounded rationality; unless you take into account limiting factors, nonlinearities and delays.

> "When we think in terms of systems, we see that a fundamental misconception is embedded in the popular term 'side-effects'...The phrase means roughly 'effects which I hadn't foreseen or don't want to think about.'...Side-effects no more deserve the adjective 'side' than does the 'principal' effect. It is hard to think in terms of systems, and we eagerly warp our language to protect ourselves from the necessity of doing so." - Garrett Hardin

> There are no separate systems. The world is a continuum. Where to draw a boundary around a system depends on the purpose of the discussion--the questions we want to ask.

> Systems analysts often fall into the opposite trap [of making boundaries too small]: making boundaries too large. They have a habit of producing diagrams that cover several pages with small print and many arrows connecting everything with everything. _There_ is the system! they say. If you have considered anything less, you are academically illegitimate.
> This "my model is bigger than your model" game results in enormously complicated analyses, which produce piles of information that may only serve to obscure the answers to the questions at hand. For example, modeling the earth's climate in full detail is interesting for many reasons, but may not be necessary for figuring out how to reduce a country's CO2 emissions to reduce climate change.

---

Chapter 5: System Traps...and Opportunities
is a very good reference for common pitfalls and opportunities in systems

Chapter 6: Leverage Points-Places to Intervene in a System
is a very good reference for approaching system problems

---

Chapter 7: Living in a World of Systems

> People who are raised in the industrial world and who get enthused about systems thinking are likely to make a terrible mistake. They are likely to assume that here, in systems analysis, in interconnection and complication, in the power of the computer, here at last, is the key to prediction and control. This mistake is likely because the mind-set of the industrial world assumes that there is a key to prediction and control.
> I assumed that at first too. We all assumed it, as eager systems students at the great institution called MIT.
> ...
> Systems thinking makes clear even to the most committed technocrat that getting along in this world of complex system requires more than technocracy.
> Self-organizing, nonlinear, feedback systems are inherently unpredictable. They are not controllable. They are understandable only in the most general way. The goal of foreseeing the future exactly and preparing for it perfectly is unrealizable. The idea of making a complex system do just what you want it to do can be achieved only temporarily, at beast. We can never fully understand our world, not in the way our reductionist science has lead us to expect. Our science itself, from quantum theory to the mathematics of chaos, leads us to irreducible uncertainty. For any objective other than the most trivial, we can't optimize; we don't even know what to optimize. We can't keep track of everything. We can't find a proper, sustainable relationship to nature, each other, or the institutions we create, if we try to do it from the role of omniscient conqueror.
> ...
> Systems thinking leads to another conclusion, however, waiting, shining, obvious, as soon as we stop being blinded by the illusion of control. It says that there is plenty to do, of a different sort of "doing." The future can't be predicted, but it can be envisioned and brought lovingly into being. Systems can't be controlled, but they can be designed and redesigned. We can't surge forward with certainty into a world of no surprises, but we can expect surprises and learn from them and even profit from them. We can't impose our will on a system. We can listen to what the system tells us, and discover how its properties and our values can work together to bring forth something much better than could ever be produced by our will alone.

...


> When we draw structural diagrams and then write equations, we are forced to make our assumptions visible and to express them with rigor. We have to put every one of our assumptions about the system out where others (and we ourselves) can see them. Our models have to be complete, and they have to add up, and they have to be consistent. Our assumptions can no longer slide around (mental models are very slippery), assuming one thing for purposes of one discussion and something else contradictory for purposes of the next discussion.

...

> Mental flexibility--the willingness to redraw boundaries, to notice that a system has shifted into a new mode, to see how to redesign structure--is a necessity when you live in a world of flexible systems.

> Remember, always, that everything you know, and everything everyone knows, is only a model. Get your model out there where it can be viewed. Invite others to challenge your assumptions and add their own. Instead of becoming a champion for one possible explanation or hypothesis or model, collect as many as possible. Consider all of them to be plausible until you find some evidence that causes you to rule one out. That way you will be emotionally able to see the evidence that rules out an assumption that may become entangled with your own identity.

(the whole chapter is great)
